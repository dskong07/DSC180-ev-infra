{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data using AFDC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import geodatasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('api_keys.json') as f:\n",
    "#    keys = json.load(f)\n",
    "#key = keys['keys']['afdc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire API key from this link: https://developer.nrel.gov/docs/\n",
    "# https://developer.nrel.gov/docs/transportation/alt-fuel-stations-v1/all/\n",
    "# note to download as json, then convert to csv in next cell\n",
    "\n",
    "\n",
    "key = 'TODO'\n",
    "api_key = key\n",
    "url_all = f'https://developer.nrel.gov/api/alt-fuel-stations/v1.json?api_key={api_key}'\n",
    "url_ev_CA = f'https://developer.nrel.gov/api/alt-fuel-stations/v1.json?api_key={api_key}&fuel_type=ELEC&state=CA&'\n",
    "url_geo_allfuels = f'https://developer.nrel.gov/api/alt-fuel-stations/v1.geojson?api_key={api_key}&state=CA'\n",
    "\n",
    "# set the filepath to save these datasets to. These datasets WILL be used in other notebooks. \n",
    "fp = 'TODO'\n",
    "fp = 'datasets/ev_stations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'fullset':url_all,\n",
    "    'ev_CA':url_ev_CA,\n",
    "}\n",
    "\n",
    "def update_datasets(urldict, fp = 'data/'):\n",
    "    for key in urldict.keys():\n",
    "\n",
    "        url = urldict[key]\n",
    "        filename = key\n",
    "\n",
    "        #just to update and skip the ones we have already\n",
    "        path = f'{fp}{filename}.csv' \n",
    "        if os.path.exists(path):\n",
    "            continue\n",
    "\n",
    "        with requests.get(url) as response:\n",
    "            data = response.json()\n",
    "        print(f\"dataset {filename} collected\")\n",
    "        \n",
    "        #uncomment if want to keep json files too (?), as this only keeps the fuelstations\n",
    "        #with open(f\"{filename}.json\", \"w\") as outfile:\n",
    "        #    json.dump(data, outfile)\n",
    "\n",
    "        df = pd.DataFrame(data['fuel_stations'])\n",
    "        df.to_csv(f'{fp}{filename}.csv')\n",
    "        print(f\"dataset {fp}{filename} saved to csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_datasets(datasets,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(f'{fp}fullset.csv')\n",
    "df_ev_CA = pd.read_csv(f'{fp}ev_CA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape, df_ev_CA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  source: https://www.pepma-ca.com/public/OtherResources.aspx?f=9KwtCRtf%2BqXCw1HmKSHHUjkyQ0VzK1rPzZozetSiP8jtWC2ehoHI6DXFZTRFfVEca3P%2B1ddq%2BkM%3D\n",
    "sdge_zips = pd.read_excel('https://www.pepma-ca.com/public/OtherResources.aspx?f=9KwtCRtf%2BqXCw1HmKSHHUjkyQ0VzK1rPzZozetSiP8jtWC2ehoHI6DXFZTRFfVEca3P%2B1ddq%2BkM%3D')\n",
    "sdge_zips = sdge_zips.ZIP_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_ev_CA[df_ev_CA.zip.isin(sdge_zips)]\n",
    "temp = temp[temp.fuel_type_code ==\"ELEC\"]\n",
    "ev_chargers_in_SDGE = temp.shape[0]\n",
    "ev_chargers_in_SDGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['street_address'].nunique()\n",
    "df_full.columns\n",
    "\n",
    "#columns we want to keep/use in this nb\n",
    "cols_keep = [\n",
    "    'fuel_type_code',\n",
    "    'status_code',\n",
    "    'open_date',\n",
    "    'expected_date',\n",
    "    'station_name',\n",
    "    'street_address',\n",
    "    'state',\n",
    "    'city',\n",
    "    'zip',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'id',\n",
    "    'ev_level1_evse_num',\n",
    "    'ev_level2_evse_num',\n",
    "    'ev_dc_fast_num',\n",
    "    'ev_other_evse'\n",
    "\n",
    "]\n",
    "def trim_cols(df):\n",
    "    return df[cols_keep]\n",
    "\n",
    "df_full = trim_cols(df_full)\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding missing values\n",
    "print(df_full.isna().sum())\n",
    "\n",
    "#notice 224 open dates missing; Note that most propane (LPG) stations do not have open dates.\n",
    "print(len(df_full[df_full.status_code == 'P']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's standardize the strings for street address. \n",
    "df_full['street_address'] = df_full['street_address'].str.lower()\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see if there are duplicates, and if so what's going on.\n",
    "print('num of street address dupes', len(df_full) - df_full.street_address.nunique())\n",
    "#seems there are quite a few duplicated street addresses - what about station names/ids? This will help us see if they're just close to each other or actually dupes.\n",
    "print('num id dupes',len(df_full) - df_full.id.nunique()) #seems that all the ids are unique.\n",
    "print('num station name dupes', len(df_full) - df_full.station_name.nunique()) #seems that there are actually some duplicate station names. Let's see what's going on?\n",
    "df_full.station_name.value_counts() #seems like there is a generic naming schema for some chargers. Let's see if these same-named chargers exist in the same location!\n",
    "dupes = df_full.groupby('station_name').street_address.value_counts().sort_values(ascending=False)\n",
    "dupes[dupes>1] #seems like there might be some actual dupes. would be interesting to look into. for now, let's take a look at the most common one: petro ontario at 4325 e guasti rd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full.station_name == 'Petro Ontario']\n",
    "#seems like they all opened on the same day, but one uses Renewable Diesel and the rest use Bio Diesel\n",
    "#for now, leave it here, might be worth investigating ways to check for actual duplicates or identify them in other ways. For now, since they all have unique IDs, they will count as individual stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating num of SDGE ev chargers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdge_ret = df_ev_CA[df_ev_CA.zip.isin(sdge_zips)]\n",
    "len(sdge_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how many of each station each state has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuels_by_state = df_full.groupby(['state','fuel_type_code']).size()\n",
    "fuels = fuels_by_state.reset_index()\n",
    "fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax = plt.subplots(figsize = (25,10))\n",
    "\n",
    "sns.histplot(\n",
    "    ax = ax,\n",
    "    data = df_full,\n",
    "    x = 'state',\n",
    "    hue = 'fuel_type_code',\n",
    "    #kind='bar'\n",
    "    multiple='dodge',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows = 7, ncols = 1, figsize = (40,40))\n",
    "\n",
    "for fuel, ax in list(zip(fuels.fuel_type_code.unique(), ax)):\n",
    "    \n",
    "    data = fuels[fuels['fuel_type_code'] == fuel]\n",
    "    ax.set_title(fuel)\n",
    "    sns.barplot(\n",
    "        ax = ax,\n",
    "        data = data,\n",
    "        x = 'state',\n",
    "        y = 0,\n",
    "        order=data.sort_values(ascending = False, by= 0).state\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting ev charging stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting geojson data \n",
    "\n",
    "with requests.get(url_geo_allfuels) as response:\n",
    "    geodata = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_usa = 'https://raw.githubusercontent.com/PublicaMundi/MappingAPI/refs/heads/master/data/geojson/us-states.json'\n",
    "with requests.get(url_usa) as response:\n",
    "    us_geo = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data from https://gis.data.ca.gov/datasets/CAEnergy::california-electric-transmission-lines-1/about\n",
    "transm_lines = gpd.GeoDataFrame.from_file('https://stg-arcgisazurecdataprod3.az.arcgis.com/exportfiles-28775-2004/Transmission_Line_-3224603581692172535.geojson?sv=2018-03-28&sr=b&sig=OzxT2oThj2qJw5jt9xCmFG%2BV%2BIftsZojexkuZA6NfM4%3D&se=2024-12-04T03%3A50%3A20Z&sp=r')\n",
    "transm_lines.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zipcode geodata from https://gis.data.ca.gov/datasets/CDEGIS::california-zip-codes/about\n",
    "zip_geodata = gpd.GeoDataFrame.from_file('https://stg-arcgisazurecdataprod3.az.arcgis.com/exportfiles-39966-259/ZipCodes_-1049704744535259894.geojson?sv=2018-03-28&sr=b&sig=8vnjMFNkWmcmve84YoHGzsaI%2F2KEFu4v9KGjuXwrXWs%3D&se=2024-12-04T03%3A52%3A50Z&sp=r')\n",
    "zip_geodata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdge_zip_geo = zip_geodata[zip_geodata['ZIP_CODE'].astype(int).isin(sdge_zips)]\n",
    "#making the geodf for sdge territory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State abbrv to name for following eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrv_to_name = {\n",
    "    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#States.\n",
    "    \"AK\": \"Alaska\",\n",
    "    \"AL\": \"Alabama\",\n",
    "    \"AR\": \"Arkansas\",\n",
    "    \"AZ\": \"Arizona\",\n",
    "    \"CA\": \"California\",\n",
    "    \"CO\": \"Colorado\",\n",
    "    \"CT\": \"Connecticut\",\n",
    "    \"DE\": \"Delaware\",\n",
    "    \"FL\": \"Florida\",\n",
    "    \"GA\": \"Georgia\",\n",
    "    \"HI\": \"Hawaii\",\n",
    "    \"IA\": \"Iowa\",\n",
    "    \"ID\": \"Idaho\",\n",
    "    \"IL\": \"Illinois\",\n",
    "    \"IN\": \"Indiana\",\n",
    "    \"KS\": \"Kansas\",\n",
    "    \"KY\": \"Kentucky\",\n",
    "    \"LA\": \"Louisiana\",\n",
    "    \"MA\": \"Massachusetts\",\n",
    "    \"MD\": \"Maryland\",\n",
    "    \"ME\": \"Maine\",\n",
    "    \"MI\": \"Michigan\",\n",
    "    \"MN\": \"Minnesota\",\n",
    "    \"MO\": \"Missouri\",\n",
    "    \"MS\": \"Mississippi\",\n",
    "    \"MT\": \"Montana\",\n",
    "    \"NC\": \"North Carolina\",\n",
    "    \"ND\": \"North Dakota\",\n",
    "    \"NE\": \"Nebraska\",\n",
    "    \"NH\": \"New Hampshire\",\n",
    "    \"NJ\": \"New Jersey\",\n",
    "    \"NM\": \"New Mexico\",\n",
    "    \"NV\": \"Nevada\",\n",
    "    \"NY\": \"New York\",\n",
    "    \"OH\": \"Ohio\",\n",
    "    \"OK\": \"Oklahoma\",\n",
    "    \"OR\": \"Oregon\",\n",
    "    \"PA\": \"Pennsylvania\",\n",
    "    \"RI\": \"Rhode Island\",\n",
    "    \"SC\": \"South Carolina\",\n",
    "    \"SD\": \"South Dakota\",\n",
    "    \"TN\": \"Tennessee\",\n",
    "    \"TX\": \"Texas\",\n",
    "    \"UT\": \"Utah\",\n",
    "    \"VA\": \"Virginia\",\n",
    "    \"VT\": \"Vermont\",\n",
    "    \"WA\": \"Washington\",\n",
    "    \"WI\": \"Wisconsin\",\n",
    "    \"WV\": \"West Virginia\",\n",
    "    \"WY\": \"Wyoming\",\n",
    "    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Federal_district.\n",
    "    \"DC\": \"District of Columbia\",\n",
    "    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Inhabited_territories.\n",
    "    \"AS\": \"American Samoa\",\n",
    "    \"GU\": \"Guam GU\",\n",
    "    \"MP\": \"Northern Mariana Islands\",\n",
    "    \"PR\": \"Puerto Rico PR\",\n",
    "    \"VI\": \"U.S. Virgin Islands\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now auto-mapping states to the names for simpler map structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all states extant in geodata\n",
    "l = geodata['features']\n",
    "key = 'state'\n",
    "states = set(x['properties'][key] for x in l)\n",
    "states\n",
    "\n",
    "\n",
    "geos_to_include = [abbrv_to_name[x] for x in states] #can include various features if needed\n",
    "geofeats = us_geo['features']\n",
    "specific_geo = [x for x in geofeats if  x['properties']['name'] in geos_to_include]\n",
    "specific_geo = {'type' : 'FeatureCollection', 'features' : specific_geo}\n",
    "geos_to_include\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USMAP = gpd.GeoDataFrame.from_features(specific_geo)\n",
    "#USMAP.set_crs(crs = 'WGS84')\n",
    "geodf = gpd.GeoDataFrame.from_features(geodata, crs = 4326)\n",
    "#geodf.set_crs(crs = 'WGS84')\n",
    "#geodf.plot(marker='*', color='green', markersize=5)\n",
    "#temp1 = geodf.to_crs(USMAP.crs)\n",
    "\n",
    "base = USMAP.plot(figsize = (20,20))\n",
    "geodf.plot(ax=base, marker='o', color='r', markersize=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out these next 2 cells are no longer needed. If there seems to be an issue with the points, uncomment and run these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "import shapely\n",
    "\n",
    "# seems that there are two points where coords are messed up... let's fix that. \n",
    "find = geodf[geodf['street_address'] == '500 Hotel Cir N']\n",
    "row = find.index\n",
    "\n",
    "pt = geodf[geodf['street_address'] == '500 Hotel Cir N']['geometry']\n",
    "print(pt)\n",
    "#seems like it's missing a negative sign in the longitude. \n",
    "\n",
    "x = pt.x\n",
    "y = pt.y\n",
    "pt = bll = shapely.Point(-x,y)\n",
    "pt\n",
    "\n",
    "geodf['geometry'][row] = pt\n",
    "r = geodf[geodf['street_address'] == '500 Hotel Cir N']\n",
    "r.geometry\n",
    "## seems first one fixed. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the second one!\n",
    "\"\"\"\n",
    "pt = geodf[geodf['street_address'] == '100 Padre Blvd']\n",
    "print(pt.geometry, pt.station_name, pt.zip, pt.city, pt.state)\n",
    "#seems like it's in texas. There doesn't exist a 100 Padre Blvd in ca, and the station name, zip, and city all line up with the texas location, not the CA one. We're just gonna drop this one.\n",
    "geodf = geodf[geodf['street_address'] != '100 Padre Blvd']\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base = USMAP.plot(figsize = (10,10), color='grey')\n",
    "geodf.plot(ax=base, marker='o', color='y', markersize=1)\n",
    "\n",
    "base = USMAP.plot(figsize = (10,10), color='grey')\n",
    "geodf.plot(ax=base, marker='o', color='y', markersize=1)\n",
    "transm_lines.plot(ax=base, linewidth = 0.5)\n",
    "#with transmission lines overlaid\n",
    "#much better. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now stratify this map by fuel type. \n",
    "\n",
    "base = USMAP.plot(figsize = (15,15), color='lightgrey')\n",
    "transm_lines.plot(ax=base, color='orange', linewidth = 0.5)\n",
    "geodf.plot(column = 'fuel_type_code', ax=base, marker='o', cmap='tab10', markersize=1.5, legend = True)\n",
    "\n",
    "#full.legend(list(fuel_dict.keys()))\n",
    "#list(fuel_dict.keys())\n",
    "# c=geodf['fuel_label_num'],cmap='prism',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a closer look at sdge territory\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "base = USMAP.plot(ax = ax, color='lightgrey')\n",
    "transm_lines.plot(ax=ax, color='orange', linewidth = 0.5)\n",
    "geodf.plot(column = 'fuel_type_code', ax=ax, marker='o', cmap='tab10', markersize=1.5, legend = True, zorder=2)\n",
    "sdge_zip_geo.plot(ax = ax, color = 'lightblue',zorder=1)\n",
    "ax.set_xlim(-118.5,-116)\n",
    "ax.set_ylim(32.5,34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to change state/add data just change the var url_geo to whatever params \n",
    "#unfortunately adding it to a figure removes the legend. \n",
    "\n",
    "\n",
    "#import folium\n",
    "\n",
    "\n",
    "sdoh = gpd.read_file(geodatasets.get_path('geoda us_sdoh'))\n",
    "trimmed_sdoh = sdoh[sdoh['state'].isin(geos_to_include)]\n",
    "m = trimmed_sdoh.explore(\n",
    "    figsize = (1200,800),\n",
    "    #cmap='Oranges',\n",
    "    column=\"ep_pci\",  # per capita income estimate\n",
    "    #scheme=\"naturalbreaks\",  # use mapclassify's natural breaks scheme\n",
    "    legend=True,  # show legend\n",
    "    k=10,  # use 10 bins\n",
    "    tooltip=False,  # hide tooltip\n",
    "    popup=[\"ep_pci\"],  # show popup (on-click)\n",
    "    legend_kwds=dict(colorbar=False),  # do not use colorbar\n",
    "    name=\"PCI\",  # name of the layer in the map\n",
    ")\n",
    "\n",
    "#f = folium.Figure(width=1200, height=800)\n",
    "geodf.explore(\n",
    "    m = m,\n",
    "    cmap = 'Oranges',\n",
    "    column = 'fuel_type_code',\n",
    "    tooltip = 'street_address',\n",
    "    #marker_type = 'circle',\n",
    "    marker_kwds=dict(radius=3, fill=False),\n",
    "    legend = True,\n",
    "    tooltip_kwds=dict(labels=False),\n",
    "    width = '100%',\n",
    "    height = '100%',\n",
    ")\n",
    "m\n",
    "# this is the fuel stations overlaid on top of a chloropleth map of estimated per capita income estimate of each region. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = zip_geodata.explore(\n",
    "    figsize = (1200,800),\n",
    "    column=\"POP_SQMI\",  # population per square mile metric for density\n",
    "    #scheme=\"naturalbreaks\",  # use mapclassify's natural breaks scheme\n",
    "    legend=True,  # show legend\n",
    "    k=10,  # use 10 bins\n",
    "    tooltip=False,  # hide tooltip\n",
    "    popup=[\"POP_SQMI\"],  # show popup (on-click)\n",
    "    legend_kwds=dict(colorbar=False),  # do not use colorbar\n",
    "    name=\"pop\",  # name of the layer in the map\n",
    "    zorder = 2\n",
    ")\n",
    "\n",
    "geodf.explore(\n",
    "    m = m1,\n",
    "    cmap = 'Oranges',\n",
    "    column = 'fuel_type_code',\n",
    "    tooltip = 'street_address',\n",
    "    marker_type = 'circle',\n",
    "    marker_kwds=dict(radius=50, fill=False),\n",
    "    legend = True,\n",
    "    tooltip_kwds=dict(labels=False),\n",
    "    width = '100%',\n",
    "    height = '100%',\n",
    "    zorder=1\n",
    ")\n",
    "m1\n",
    "\n",
    "#stations overlaid against population density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary takeaways and insights from geographical data analysis:\n",
    "Most notably from the above two interactive maps, it seems that while fuel stations are often NEARBY higher per capita income zones, it is less common that they actually are INSIDE the wealthiest locales; from the second map m1 above, the stations appear to be clustered around higher population density locations, as well as generally along major motorways. This makes sense, as higher population locations are usually urban areas, and the more people there are in a certain location, the more vehicle owners there will be. Additionally, from the static maps above, we can see that EV chargers follow closely along major power transmission lines. Again, this makes perfect sense, as EV chargers are by nature held in lockstep by the local energy infrastructure. To perform additional research and hypothesis testing on these assertions, I believe it would be valuable to look at data containing EV sales by zip code to see if the distributions line up with the fuel station densities we see here. As for the EV charger location in relation to power lines, I think it would be interesting to plot traditional gasoline pumps, simply to see if the power lines follow places people travel more commonly, and if the clustering and distribution is actually a function of throughput traffic rather than infrastructure design. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts_df = df_full[['state', 'open_date','fuel_type_code']]\n",
    "ts_df['station_added'] = np.ones(ts_df.shape[0])\n",
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = ts_df.dropna()\n",
    "ts = pd.Series(data = ts_df['station_added'])\n",
    "ts.index = ts_df['open_date']\n",
    "ts.sort_index()\n",
    "# DATE input error..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing date error \n",
    "dates = ts_df['open_date']\n",
    "dates = dates.replace('^00', '20', regex = True)\n",
    "dates = pd.to_datetime(dates, format ='mixed')\n",
    "\n",
    "#indexing vals by date\n",
    "ts_df = ts_df.drop('open_date', axis = 1).set_index(dates)\n",
    "ts_df = ts_df.sort_index()\n",
    "\n",
    "ts = pd.Series(data = ts_df['station_added'])\n",
    "ts = ts.sort_index()\n",
    "ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts.cumsum().plot(xlim=(min(ts.index),datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = ts_df[['state','station_added']]\n",
    "ts_df.groupby('state').sum().sort_values('station_added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df[ts_df.state == 'OH'].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "for cur_state in ts_df.state.unique():\n",
    "    ts_df[ts_df.state==cur_state].cumsum().plot(ax=ax, label = f'{cur_state}',xlim=(min(ts.index),datetime.datetime.now()))\n",
    "ax.legend(ts_df.state.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,15))\n",
    "ax.set_yscale('log')\n",
    "#ax.set_xticks(list(np.arange(min(ts.index.year),max(ts.index.year),1)),labels=np.arange(min(ts.index.year),max(ts.index.year),1))\n",
    "for cur_state in ts_df.state.unique():\n",
    "    ts_df[ts_df.state==cur_state].cumsum().plot(ax=ax, label = f'{cur_state}',xlim=(min(ts.index),datetime.datetime.now()),grid=True)\n",
    "ax.legend(ts_df.state.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary takeaways/insights from time series analysis:\n",
    "\n",
    "We can see that from the linear y axis line graph that there is a general trend of exponential increase across the board in alternative fuel stations for every state, with california leading the pack. However, by plotting the y-axis with a logarithmic scale, we can see that there are some periods of extreme growth across many states, creating a vertical jump in the number of stations. These time periods slightly vary among state, but there are a few periods that are basically unanimous, such as late 1999-2001, 2005-2006, 2012-2013, and 2021-2022. My current hypothesis is that:\n",
    "1. these are related to national government policies, such as national subsidies for clean energy infrastructure\n",
    "2. these are related to more widespread low emmision vehicle adoption\n",
    "3. these are related to upgrades in the energy infrastructure across the nation\n",
    "We could investigate these ideas by looking at government policy enactments surrounding these time frames, study overall clean energy vehicle sales, or investigating energy infrastructure upgrade reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.system('jupyter nbconvert --to html EDA.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
